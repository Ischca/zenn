---
title: "Claude Code実践ガイド: 品質ゲートの設計"
emoji: "✅"
type: "tech"
topics: ["claudecode", "ai", "cli", "開発ツール"]
published: false
---

## はじめに

AIが生成したコード、そのまま使っていいのか。
何かしらのチェックを挟んだ方が安心です。
この記事では、Claude Codeの出力品質を担保するための「品質ゲート」という考え方と、その実装方法について整理します。

## 品質ゲートとは

品質ゲートとは、次の工程に進む前に満たすべき基準のことです。ソフトウェア開発では、CI/CDパイプラインでのテストやlintが代表例です。

AIエージェントを使う開発でも、この考え方は重要です。エージェントが生成したコードをそのままマージすると、品質にばらつきが出ます。一定の基準を満たすまで先に進めない仕組みを作ることで、安定した品質を維持できます。

## Claude CodeのHooksとは

Claude Codeには「Hooks」という仕組みがあり、特定のイベントに応じて自動でコマンドを実行できます。

[公式ドキュメント](https://code.claude.com/docs/en/features-overview)では次のように説明されています：

> Hooksは`.claude/settings.json`で設定されたカスタムコマンドで、ツールイベントに応答して実行される

これを使えば、「ファイル編集後にlintを自動実行」「コミット前にテストを自動実行」といった品質ゲートを自動化できます。

[Builder.ioのガイド](https://www.builder.io/blog/claude-code)では、Hooksの具体例を以下のように紹介しています：

> 編集が受け入れられる前に実行すべきコード（特定のファイルにPrettierを実行するなど）や、編集後に実行すべきコード（特定のファイルに型チェックを実行して、正しいファイルだけを受け入れるようにするなど）のフックを追加します。

## なぜ品質ゲートが必要か

### エージェント出力の品質ばらつき

AIエージェントの出力品質は一定ではありません。同じ指示でも、コンテキストの状態や偶発的な要因で結果が変わることがあります。品質ゲートを設けることで、一定基準を満たさない出力がマージされるのを防げます。

### 暗黙のルールの明示化

チームには暗黙のコーディングルールがあります。これをCLAUDE.mdに書いていても、エージェントが見落とすことはあります。lint/formatter/型チェックで機械的にチェックできる部分は自動化しておくべきです。

### 人間の確認ポイントの明確化

全てを人間がチェックするのは非効率です。機械でチェックできる部分は機械に任せ、人間は「意図通りか」「設計として正しいか」といった判断に集中できます。

## ローカルでの品質チェック

### 基本のチェック項目

実装が終わったら、まずローカルで以下を確認します：
- lint通過
- テスト通過
- 型チェック通過
- ビルド成功

エージェントに「lint、テスト、型チェックを実行して、全て通ることを確認してからコミットして」と指示します。

### Hooksでの自動化

`.claude/settings.json`でHooksを設定できます：

```json
{
  "hooks": {
    "postEdit": ["npm run lint --fix"],
    "preCommit": ["npm test"]
  }
}
```

これにより、ファイル編集後に自動でlintが走り、コミット前に自動でテストが走ります。

## CIでの自動チェック

### 基本構成

CIパイプラインでは、ローカルと同じチェックに加えて追加の検証を行います。

基本のチェック：
- lint
- テスト（ユニット、インテグレーション、E2E）
- 型チェック
- ビルド

追加で検討するチェック：
- セキュリティスキャン（依存関係の脆弱性）
- コードカバレッジ
- パフォーマンス回帰テスト

### CIでClaudeにレビューさせる

Claude Codeはヘッドレスモードで動作できるため、CIから呼び出すことが可能です。

[公式ドキュメント](https://code.claude.com/docs/en/overview)では次のように述べています：

> Unix哲学：Claude Codeはコンポーザブルでスクリプト可能です。`tail -f app.log | claude -p "このログストリームに異常が現れたらSlackに通知して"`が動作します。CIで`claude -p "新しいテキスト文字列があれば、フランス語に翻訳して@lang-fr-teamにレビュー用のPRを作成して"`を実行できます。

PR作成時にClaudeを動かし、以下の観点でレビューさせることができます：
- セキュリティ（脆弱性、認証・認可の問題）
- パフォーマンス（N+1クエリ、不要なループ）
- 既存機能との整合性（破壊的変更がないか）

## セルフレビューのスキル化

実装後のセルフレビューは、前回紹介したスキルとして定義しておくと便利です。

```markdown
---
name: self-review
description: 実装後のセルフレビュー。コミット前に使用。
---

## レビュー手順
1. `git diff`で変更内容を確認
2. 以下の観点でチェック

## チェック観点
### コードレベル
- 命名規則の遵守
- 関数の責務が明確か
- エラーハンドリングが適切か

### 仕様レベル
- 要求された機能を満たしているか
- エッジケースを考慮しているか

問題があれば指摘し、修正案を提示する。
```

## テスト戦略とフェーズ

プロジェクトのフェーズによって、テストの重点は変わります。

**0→1（プロトタイプ期）**
- クリティカルな箇所に限定してテスト
- 動くことの確認が優先

**安定化期**
- ユニットテスト＋E2Eを拡充
- リグレッション検知を重視

**運用期**
- カバレッジの維持
- パフォーマンス監視の追加

エージェントにテストを書かせる際も、このフェーズを意識します。プロトタイプ期に網羅的なテストを書かせても、仕様変更で無駄になる可能性が高いです。

## 偽陽性への対策

テストやCIで「偽陽性」（本当は問題ないのに失敗する）が多いと、チェックが形骸化します。

偽陽性が起きやすいパターン：
- モックが実態と乖離している
- タイミング依存のテスト（flaky test）
- 環境差異による失敗

対策：
- 本番に近い環境でテストする
- リトライ、タイムアウト、シード固定でフレーク対策
- モックより実際のI/Oを使う比率を上げる

## まとめ

- 品質ゲートは次工程に進む前に満たすべき基準
- Hooksを使ってローカルでの品質チェックを自動化できる
- CIでClaudeにレビューさせることも可能
- セルフレビューをスキル化して観点を標準化
- プロジェクトのフェーズに応じてテスト戦略を調整
